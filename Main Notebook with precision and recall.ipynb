{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f096d7-10e2-46cf-8585-f26f401ba090",
   "metadata": {
    "id": "74f096d7-10e2-46cf-8585-f26f401ba090"
   },
   "source": [
    "# 1. Modellevaluierung fÃ¼r Option 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddd8232-3bb0-4279-aa58-8c99b3d1b977",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "bddd8232-3bb0-4279-aa58-8c99b3d1b977",
    "outputId": "1b2f930e-9510-4ef4-8f74-95b074cca101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.1-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "Collecting numpy>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting scipy>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: smart-open, numpy, scipy, gensim\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 6.3.0\n",
      "    Uninstalling smart-open-6.3.0:\n",
      "      Successfully uninstalled smart-open-6.3.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.1\n",
      "    Uninstalling gensim-4.3.1:\n",
      "      Successfully uninstalled gensim-4.3.1\n",
      "Successfully installed gensim-4.3.1 numpy-1.24.3 scipy-1.10.1 smart-open-6.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40098027-2663-43a4-965d-93fba60db100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40098027-2663-43a4-965d-93fba60db100",
    "outputId": "beb878f0-3f10-4631-82d4-bb003dc57a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vVLXXj1lxA-B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "vVLXXj1lxA-B",
    "outputId": "6bc4e0c5-02cd-49bd-e81f-91b2a96914a8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    " \n",
    " \n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "HgjNb_t9xbLs",
   "metadata": {
    "id": "HgjNb_t9xbLs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f46d7a0-4fe5-40ed-9148-f11620646145",
   "metadata": {
    "id": "2f46d7a0-4fe5-40ed-9148-f11620646145"
   },
   "outputs": [],
   "source": [
    "def helper(column):\n",
    "    return str(column).split(\",\")\n",
    "\n",
    "def open_csv_default():\n",
    "    df_data = pd.read_csv(\"naukri_data_science_jobs_india.csv\")\n",
    "    df_data = df_data.drop(columns=['Company', 'Location', 'Job Experience'])\n",
    "    df_data[\"Skills/Description\"] =df_data[\"Skills/Description\"].apply(lambda x : helper(x))\n",
    "    return df_data\n",
    "\n",
    "'''\n",
    "def open_csv_clean():\n",
    "    df_data = pd.read_csv(\"naukri_data_science_jobs_india_cleaned.csv\")\n",
    "    #df_data = df_data.drop(columns=['Company', 'Location', 'Job Experience'])\n",
    "    #df_data[\"Skills/Description\"] =df_data[\"Skills/Description\"].apply(lambda x : helper(x))\n",
    "    return df_data\n",
    "'''\n",
    "\n",
    "def open_csv_clean():\n",
    "    df_data = pd.read_csv(\"naukri_data_science_jobs_india_cleaned.csv\")\n",
    "    formatted = df_data.values.tolist()\n",
    "    return formatted\n",
    "\n",
    "def open_csv_clustered():\n",
    "    df_data = pd.read_csv(\"naukri_data_science_jobs_india_cleaned_clusterd.csv\")\n",
    "    df_data = df_data.drop(columns=['Job_Role', 'lda_score'])\n",
    "    df_data = df_data[['lda_topic', 'Skills/Description']]\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2camXPYwVlp",
   "metadata": {
    "id": "d2camXPYwVlp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Option 1: Use Doc2Vec which includes the \"document title\" in learning.\\n## Works out of the box\\n\\nfrom gensim.models import Doc2Vec\\nfrom gensim.models.doc2vec import TaggedDocument\\nimport ast\\n\\n#data = open_csv_default()\\ndata = open_csv_clean()\\n\\n# Preprocess the data and create TaggedDocuments\\n#tagged_data = [TaggedDocument(words=skills, tags = [job]) for skills in data]\\n#tagged_data = [TaggedDocument(words=skills, tags=[job]) for job, skills in data]\\ntagged_data = [TaggedDocument(words=ast.literal_eval(skills), tags=[job]) for job, skills in data]\\n\\n# Train the Doc2Vec model\\nmodel = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\\nmodel.build_vocab(tagged_data)\\n\\nmodel.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### Option 1: Use Doc2Vec which includes the \"document title\" in learning.\n",
    "## Works out of the box\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import ast\n",
    "\n",
    "#data = open_csv_default()\n",
    "data = open_csv_clean()\n",
    "\n",
    "# Preprocess the data and create TaggedDocuments\n",
    "#tagged_data = [TaggedDocument(words=skills, tags = [job]) for skills in data]\n",
    "#tagged_data = [TaggedDocument(words=skills, tags=[job]) for job, skills in data]\n",
    "tagged_data = [TaggedDocument(words=ast.literal_eval(skills), tags=[job]) for job, skills in data]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ITVnx__eycag",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITVnx__eycag",
    "outputId": "ff5c34a4-2ee7-4ce6-f0f9-297147ed8024"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy\\n\\n# Test the model\\n#print(model.wv[\"python\"])\\nprint(numpy.linalg.norm(model.wv[\"advanced_analytics\"] - model.wv[\"analytics\"]))\\nprint(numpy.linalg.norm(model.wv[\"machine_learning\"] - model.wv[\"management\"]))\\n\\n# Enter skills and get most suitable jobs\\nskills = [\\'machine_learning\\', \\'advanced_analytics\\']\\ninfer_vector = model.infer_vector(skills)\\nsimilar_jobs = model.dv.most_similar([infer_vector], topn=5)\\n\\nprint(f\"Given skills: {skills}\")\\nprint(\"Most suitable jobs:\")\\nfor job, similarity in similar_jobs:\\n    print(f\"- {job} (Similarity: {similarity:.2f})\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy\n",
    "\n",
    "# Test the model\n",
    "#print(model.wv[\"python\"])\n",
    "print(numpy.linalg.norm(model.wv[\"advanced_analytics\"] - model.wv[\"analytics\"]))\n",
    "print(numpy.linalg.norm(model.wv[\"machine_learning\"] - model.wv[\"management\"]))\n",
    "\n",
    "# Enter skills and get most suitable jobs\n",
    "skills = ['machine_learning', 'advanced_analytics']\n",
    "infer_vector = model.infer_vector(skills)\n",
    "similar_jobs = model.dv.most_similar([infer_vector], topn=5)\n",
    "\n",
    "print(f\"Given skills: {skills}\")\n",
    "print(\"Most suitable jobs:\")\n",
    "for job, similarity in similar_jobs:\n",
    "    print(f\"- {job} (Similarity: {similarity:.2f})\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4z3acAgC4Qf",
   "metadata": {
    "id": "d4z3acAgC4Qf"
   },
   "outputs": [],
   "source": [
    "### Training uses the Doc2Vec or Word2Vec model which simply embeds words according to how often they occur together (ignoring order afaik)\n",
    "## Adapt vector size and epochs in training once data set is complete\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import ast\n",
    "import numpy\n",
    "\n",
    "def trainWord2Vec(data):\n",
    "# Preprocess the data and create list of skills (this training does NOT include jobs!)\n",
    "    tagged_data = [ast.literal_eval(skills) for job, skills in data]\n",
    "\n",
    "# Train the Word2Vec model, try different vector sizes for interesting effects in similarities\n",
    "    model = Word2Vec(vector_size=50, min_count=1, workers=4, epochs=20)\n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def trainDoc2Vec(data):\n",
    "    tagged_data = [TaggedDocument(words=ast.literal_eval(skills), tags=[job]) for job, skills in data[:]]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# helper method to calculate average embedding vector of a list of string skills, filters out skills unknown to the model\n",
    "def averageOfSkills(model, input, axis = 0):\n",
    "    vectors = [model.wv[i] for i in input if model.wv.has_index_for(i)]\n",
    "    if(len(vectors) == 0):\n",
    "        return numpy.zeros(len(model.wv[0]))\n",
    "    \n",
    "    return numpy.average(vectors, axis = axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eRXCk52dDg83",
   "metadata": {
    "id": "eRXCk52dDg83"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def calcAvgEmbeddings(model, data):\n",
    "\n",
    "    # Tests for the embedding go here\n",
    "    print(model.wv.most_similar(\"neural_networks\", topn = 5))\n",
    "\n",
    "    #cosine distance\n",
    "    print(model.wv.distance(\"finance\", \"machine_learning\"))\n",
    "    print(model.wv.distance(\"ai\", \"machine_learning\"))\n",
    "    print(model.wv.distance(\"business_intelligence\", \"management\"))\n",
    "    print(model.wv.distance('corporate_governance', 'ai'))\n",
    "    #euclidean distance\n",
    "    #print(numpy.linalg.norm(model.wv[\"statistics\"] - model.wv[\"machine_learning\"]))\n",
    "\n",
    "    # split the tuples\n",
    "    job_titles, skills = list(zip(*data))\n",
    "    # calculate the average skill vector of every job offering / person and zip back together\n",
    "    skillAverages = [averageOfSkills(model, ast.literal_eval(skill)) for skill in skills]\n",
    "    data_averaged = list(zip(job_titles, skillAverages))\n",
    "\n",
    "    return (skillAverages, data_averaged)\n",
    "\n",
    "# This gives us a list of job offerings and average embeddings. \n",
    "# Could be used as input to a graph neural network or knowledge graph?\n",
    "# Is used below to classify immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6MOCIrZkKbDX",
   "metadata": {
    "id": "6MOCIrZkKbDX"
   },
   "outputs": [],
   "source": [
    "# simply suggest smallest distance to user's average (\"Option 2\") using word2Vec\n",
    "import itertools\n",
    "import operator\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def prepareOption2(data):\n",
    "\n",
    "    model = trainWord2Vec(data)\n",
    "    skillAverages, data_averaged = calcAvgEmbeddings(model, data)\n",
    "\n",
    "    # sort before grouping\n",
    "    data_averaged.sort(key=operator.itemgetter(0))\n",
    "    # Group by job title, take the average embedding of everyone with that title and make a dictionary (maps job title to average embedding)\n",
    "    job_averages = {key : numpy.average(list(zip(*list(value)))[1], axis = 0)\n",
    "        for key, value in itertools.groupby(data_averaged, lambda x: x[0])}\n",
    "\n",
    "    #keep keys and values\n",
    "    keys = list(job_averages.keys())\n",
    "    values = list(job_averages.values())\n",
    "    # easy access to the avg vector\n",
    "    #print(job_averages['Advisor, Data Science'])\n",
    "    \n",
    "    # model.save(\"word2vec_model_option2.bin\")\n",
    "\n",
    "    return job_averages, keys, values, model\n",
    "\n",
    "# usage in next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eYYHhscDE1vV",
   "metadata": {
    "id": "eYYHhscDE1vV"
   },
   "outputs": [],
   "source": [
    "# \"Option 3\" could be using the embedding learned by Doc2Vec and doing the same manual averaging as Option 2 for \"learning\" the correlation of job to skills\n",
    "import itertools\n",
    "import operator\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def prepareOption3(data):\n",
    "#if !data:\n",
    "#  data = open_csv_clean()\n",
    "\n",
    "    model = trainDoc2Vec(data)\n",
    "    skillAverages, data_averaged = calcAvgEmbeddings(model, data)\n",
    "\n",
    "    # sort before grouping\n",
    "    data_averaged.sort(key=operator.itemgetter(0))\n",
    "    # Group by job title, take the average embedding of everyone with that title and make a dictionary (maps job title to average embedding)\n",
    "    job_averages = {key : numpy.average(list(zip(*list(value)))[1], axis = 0)\n",
    "        for key, value in itertools.groupby(data_averaged, lambda x: x[0])}\n",
    "\n",
    "    #keep keys and values\n",
    "    keys = list(job_averages.keys())\n",
    "    values = list(job_averages.values())\n",
    "    \n",
    "    # model.save(\"doc2vec_model_option3.bin\")\n",
    "\n",
    "    return job_averages, keys, values, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "WW1p_fgqFIws",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WW1p_fgqFIws",
    "outputId": "7b273ef3-9ecc-4400-d7bb-5ce1eb1a33da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# USAGE of Option 2 and 3:\\n# (not a proper test yet)\\n\\n\\n# data = open_csv_clean()\\n# formatted = data.values.tolist()\\nformatted = open_csv_clean()\\n\\n\\n\\njob_averages, keys, values, model = prepareOption3(data)\\n#job_averages, keys, values, model = prepareOption2(data)\\n\\n#Given some skill list:\\n#my_skills = [\"business_intelligence\", \"management\"]\\nmy_skills = [\\'python\\', \\'tableau\\', \\'machine_learning\\', \\'sql\\', \\'statistical_modeling\\', \\'adv_excel\\', \\'microstrategy\\', \\'r_shiny\\']\\n# we can calculate the average embedding\\navg = averageOfSkills(model, my_skills)\\n\\n#and match it to the closest job title\\n# calculate distance to all jobs for lack of better solution, optimize this if there\\'s time\\ndistVec = cdist([avg], values)\\n# zip the distances with the keys and sort jobs by distance\\nsortedList = sorted(list(zip(distVec.transpose(), keys)))\\n# print top 5 scoring jobs (i.e. smallest distance)\\nresult = [(\"\" + str(i) +\": Score \" + str(1 / max(scor[0], 0.1))) for scor,i in sortedList[0:5]]\\n#result = [(\"\" + str(i) +\": Score \" + str(scor)) for scor,i in sortedList[0:5]]\\nprint(\"Top Jobs: \")\\nfor i in range(5):\\n    print(result[i])\\n\\n# Our model option 2 should immediately support another application: Find top 10 skills of some job\\n\\njob = \"Data Manager\"\\n\\nembed = job_averages[job]\\n\\nembed = embed / numpy.linalg.norm(embed)\\n\\ndistVec = cdist([embed], model.wv.get_normed_vectors())\\n\\nprint(distVec.shape)\\nprint(len(distVec))\\n\\nsortIndicesByDist = sorted(list(zip(distVec.transpose(), range(len(distVec.transpose())))))\\nresult = [(model.wv.index_to_key[index], score) for score,index in sortIndicesByDist[0:10]]\\n\\nprint(\"Main skills for \"+ job)\\nfor i in range(10):\\n    print(result[i])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# USAGE of Option 2 and 3:\n",
    "# (not a proper test yet)\n",
    "\n",
    "\n",
    "# data = open_csv_clean()\n",
    "# formatted = data.values.tolist()\n",
    "formatted = open_csv_clean()\n",
    "\n",
    "\n",
    "\n",
    "job_averages, keys, values, model = prepareOption3(data)\n",
    "#job_averages, keys, values, model = prepareOption2(data)\n",
    "\n",
    "#Given some skill list:\n",
    "#my_skills = [\"business_intelligence\", \"management\"]\n",
    "my_skills = ['python', 'tableau', 'machine_learning', 'sql', 'statistical_modeling', 'adv_excel', 'microstrategy', 'r_shiny']\n",
    "# we can calculate the average embedding\n",
    "avg = averageOfSkills(model, my_skills)\n",
    "\n",
    "#and match it to the closest job title\n",
    "# calculate distance to all jobs for lack of better solution, optimize this if there's time\n",
    "distVec = cdist([avg], values)\n",
    "# zip the distances with the keys and sort jobs by distance\n",
    "sortedList = sorted(list(zip(distVec.transpose(), keys)))\n",
    "# print top 5 scoring jobs (i.e. smallest distance)\n",
    "result = [(\"\" + str(i) +\": Score \" + str(1 / max(scor[0], 0.1))) for scor,i in sortedList[0:5]]\n",
    "#result = [(\"\" + str(i) +\": Score \" + str(scor)) for scor,i in sortedList[0:5]]\n",
    "print(\"Top Jobs: \")\n",
    "for i in range(5):\n",
    "    print(result[i])\n",
    "\n",
    "# Our model option 2 should immediately support another application: Find top 10 skills of some job\n",
    "\n",
    "job = \"Data Manager\"\n",
    "\n",
    "embed = job_averages[job]\n",
    "\n",
    "embed = embed / numpy.linalg.norm(embed)\n",
    "\n",
    "distVec = cdist([embed], model.wv.get_normed_vectors())\n",
    "\n",
    "print(distVec.shape)\n",
    "print(len(distVec))\n",
    "\n",
    "sortIndicesByDist = sorted(list(zip(distVec.transpose(), range(len(distVec.transpose())))))\n",
    "result = [(model.wv.index_to_key[index], score) for score,index in sortIndicesByDist[0:10]]\n",
    "\n",
    "print(\"Main skills for \"+ job)\n",
    "for i in range(10):\n",
    "    print(result[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffC6pZCMFed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ffC6pZCMFed",
    "outputId": "9429fbfd-cfa3-43a1-f046-255e2e21d050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Proper testing\\nimport heapq\\n\\n# divide data into 75 train, 25 test\\ndef train_test_split(df, frac=0.25):\\n    \\n    # get random sample \\n    test = df.sample(frac=frac, axis=0)\\n\\n    # get everything but the test sample\\n    train = df.drop(index=test.index)\\n\\n    return train, test\\n\\ndf = open_csv_clustered()\\n\\ndf_data, df_test = train_test_split(df)\\n\\nformatted_data = df_data.values.tolist()\\nformatted_test = df_test.values.tolist()\\njobs, skills = list(zip(*formatted_test))\\nskills = [ast.literal_eval(skill) for skill in skills]\\n\\nprint(len(skills))\\n\\noption = 2\\n#Doc2Vec\\nif option == 1:\\n    model = trainDoc2Vec(formatted_data)\\n    correct = 0\\n    top3 = 0\\n    for i in range(len(jobs)):\\n        infer_vector = model.infer_vector(skills[i])\\n        similar_jobs = model.dv.most_similar([infer_vector], topn=3)\\n        if(similar_jobs[0][0] == jobs[i]):\\n            correct = correct + 1\\n            top3 = top3 + 1\\n        elif(any(item[0] == jobs[i] for item in similar_jobs)):\\n            top3 = top3 + 1\\n        resultCorrect = correct / len(jobs)\\n        resultTop3 = top3 / len(jobs)\\n        print(\"Option 1: Percent of correct guesses: \" + str(resultCorrect) + \", percent of top 3 guesses: \" + str(resultTop3))\\n\\n#Word2Vec\\nelif option == 2:\\n    job_averages, keys, values, model = prepareOption2(formatted_data)\\n    correct = 0\\n    top3 = 0\\n    for i in range(len(jobs)):\\n        avg = averageOfSkills(model, skills[i])\\n        distVec = cdist([avg,], values)\\n        #sortedList = sorted(list(zip(distVec.transpose(), keys)))\\n        #topJobs = [i for scor,i in sortedList[0:5]]\\n        topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\\n        if(topJobs[0] == jobs[i]):\\n            correct = correct + 1\\n            top3 = top3 + 1\\n        elif(jobs[i] in topJobs):\\n            top3 = top3 + 1\\n    resultCorrect = correct / len(jobs)\\n    resultTop3 = top3 / len(jobs)\\n    print(\"Option 2: Rate of correct guesses: \" + str(resultCorrect) + \", rate of top 3 guesses: \" + str(resultTop3))\\nelif option == 3:\\n    job_averages, keys, values, model = prepareOption3(formatted_data)\\n    correct = 0\\n    top3 = 0\\n    for i in range(len(jobs)):\\n        avg = averageOfSkills(model, skills[i])\\n        distVec = cdist([avg,], values)\\n        #sortedList = sorted(list(zip(distVec.transpose(), keys)))\\n        #topJobs = [i for scor,i in sortedList[0:5]]\\n        topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\\n        if(topJobs[0] == jobs[i]):\\n            correct = correct + 1\\n            top3 = top3 + 1\\n        elif(jobs[i] in topJobs):\\n            top3 = top3 + 1\\n    resultCorrect = correct / len(jobs)\\n    resultTop3 = top3 / len(jobs)\\n    print(\"Option 3: Rate of correct guesses: \" + str(resultCorrect) + \", rate of top 3 guesses: \" + str(resultTop3))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Proper testing\n",
    "import heapq\n",
    "\n",
    "# divide data into 75 train, 25 test\n",
    "def train_test_split(df, frac=0.25):\n",
    "    \n",
    "    # get random sample \n",
    "    test = df.sample(frac=frac, axis=0)\n",
    "\n",
    "    # get everything but the test sample\n",
    "    train = df.drop(index=test.index)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "df = open_csv_clustered()\n",
    "\n",
    "df_data, df_test = train_test_split(df)\n",
    "\n",
    "formatted_data = df_data.values.tolist()\n",
    "formatted_test = df_test.values.tolist()\n",
    "jobs, skills = list(zip(*formatted_test))\n",
    "skills = [ast.literal_eval(skill) for skill in skills]\n",
    "\n",
    "print(len(skills))\n",
    "\n",
    "option = 2\n",
    "#Doc2Vec\n",
    "if option == 1:\n",
    "    model = trainDoc2Vec(formatted_data)\n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    for i in range(len(jobs)):\n",
    "        infer_vector = model.infer_vector(skills[i])\n",
    "        similar_jobs = model.dv.most_similar([infer_vector], topn=3)\n",
    "        if(similar_jobs[0][0] == jobs[i]):\n",
    "            correct = correct + 1\n",
    "            top3 = top3 + 1\n",
    "        elif(any(item[0] == jobs[i] for item in similar_jobs)):\n",
    "            top3 = top3 + 1\n",
    "        resultCorrect = correct / len(jobs)\n",
    "        resultTop3 = top3 / len(jobs)\n",
    "        print(\"Option 1: Percent of correct guesses: \" + str(resultCorrect) + \", percent of top 3 guesses: \" + str(resultTop3))\n",
    "\n",
    "#Word2Vec\n",
    "elif option == 2:\n",
    "    job_averages, keys, values, model = prepareOption2(formatted_data)\n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    for i in range(len(jobs)):\n",
    "        avg = averageOfSkills(model, skills[i])\n",
    "        distVec = cdist([avg,], values)\n",
    "        #sortedList = sorted(list(zip(distVec.transpose(), keys)))\n",
    "        #topJobs = [i for scor,i in sortedList[0:5]]\n",
    "        topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\n",
    "        if(topJobs[0] == jobs[i]):\n",
    "            correct = correct + 1\n",
    "            top3 = top3 + 1\n",
    "        elif(jobs[i] in topJobs):\n",
    "            top3 = top3 + 1\n",
    "    resultCorrect = correct / len(jobs)\n",
    "    resultTop3 = top3 / len(jobs)\n",
    "    print(\"Option 2: Rate of correct guesses: \" + str(resultCorrect) + \", rate of top 3 guesses: \" + str(resultTop3))\n",
    "elif option == 3:\n",
    "    job_averages, keys, values, model = prepareOption3(formatted_data)\n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    for i in range(len(jobs)):\n",
    "        avg = averageOfSkills(model, skills[i])\n",
    "        distVec = cdist([avg,], values)\n",
    "        #sortedList = sorted(list(zip(distVec.transpose(), keys)))\n",
    "        #topJobs = [i for scor,i in sortedList[0:5]]\n",
    "        topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\n",
    "        if(topJobs[0] == jobs[i]):\n",
    "            correct = correct + 1\n",
    "            top3 = top3 + 1\n",
    "        elif(jobs[i] in topJobs):\n",
    "            top3 = top3 + 1\n",
    "    resultCorrect = correct / len(jobs)\n",
    "    resultTop3 = top3 / len(jobs)\n",
    "    print(\"Option 3: Rate of correct guesses: \" + str(resultCorrect) + \", rate of top 3 guesses: \" + str(resultTop3))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "LA8npAnMSkW6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LA8npAnMSkW6",
    "outputId": "ed793db2-71c2-4631-d83c-eb1b0cbed214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn the following, I will try to calculate:\\nâ¢\\tCondition positive (P): The number of real positive cases in the data.\\nâ¢\\tCondition negative (N): The number of real negative cases in the data.\\nâ¢\\tTrue positive (TP): A test result that correctly indicates the presence of a condition or characteristic.\\nâ¢\\tTrue negative (TN): A test result that correctly indicates the absence of a condition or characteristic.\\nâ¢\\tFalse positive (FP): A test result that wrongly indicates that a particular condition or attribute is present.\\nâ¢\\tFalse negative (FN): A test result that wrongly indicates that a particular condition or attribute is absent.\\nâ¢\\tSensitivity, recall, hit rate, or true positive rate (TPR): The proportion of true positives out of all actual positive cases.\\nâ¢\\tSpecificity, selectivity, or true negative rate (TNR): The proportion of true negatives out of all actual negative cases.\\nâ¢\\tPrecision or positive predictive value (PPV): The proportion of true positives out of all positive predictions made by the model.\\nâ¢\\tNegative predictive value (NPV): The proportion of true negatives out of all negative predictions made by the model.\\nâ¢\\tMiss rate or false negative rate (FNR): The proportion of false negatives out of all actual positive cases.\\nâ¢\\tFall-out or false positive rate (FPR): The proportion of false positives out of all actual negative cases.\\nâ¢\\tFalse discovery rate (FDR): The proportion of false positives out of all positive predictions made by the model.\\nâ¢\\tFalse omission rate (FOR): The proportion of false negatives out of all negative predictions made by the model.\\nâ¢\\tPositive likelihood ratio (LR+): The ratio of true positive rate to false positive rate.\\nâ¢\\tNegative likelihood ratio (LR-): The ratio of false negative rate to true negative rate.\\nâ¢\\tPrevalence threshold (PT): A threshold value that balances sensitivity and specificity.\\nâ¢\\tThreat score (TS) or critical success index (CSI): The proportion of true positives out of all positive and negative predictions made by the model.\\nâ¢\\tPrevalence: The proportion of positive cases in the data.\\nâ¢\\tAccuracy (ACC): The proportion of correct predictions (both true positives and true negatives) out of all predictions made by the model.\\nâ¢\\tBalanced accuracy (BA): The average of sensitivity and specificity.\\nâ¢\\tF1 score: The harmonic mean of precision and sensitivity, providing a single metric to balance both.\\nâ¢\\tPhi coefficient (Ï) or Matthews correlation coefficient (MCC): A correlation coefficient that takes into account true positives, true negatives, false positives, and false negatives.\\nâ¢\\tFowlkes-Mallows index (FM): A geometric mean of precision and sensitivity.\\nâ¢\\tInformedness or bookmaker informedness (BM): The sum of true positive rate and true negative rate, minus 1.\\nâ¢\\tMarkedness (MK) or deltaP (Îp): The sum of positive predictive value and negative predictive value, minus 1.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation and assessment of binary classification models\n",
    "\n",
    "'''\n",
    "In the following, I will try to calculate:\n",
    "â¢\tCondition positive (P): The number of real positive cases in the data.\n",
    "â¢\tCondition negative (N): The number of real negative cases in the data.\n",
    "â¢\tTrue positive (TP): A test result that correctly indicates the presence of a condition or characteristic.\n",
    "â¢\tTrue negative (TN): A test result that correctly indicates the absence of a condition or characteristic.\n",
    "â¢\tFalse positive (FP): A test result that wrongly indicates that a particular condition or attribute is present.\n",
    "â¢\tFalse negative (FN): A test result that wrongly indicates that a particular condition or attribute is absent.\n",
    "â¢\tSensitivity, recall, hit rate, or true positive rate (TPR): The proportion of true positives out of all actual positive cases.\n",
    "â¢\tSpecificity, selectivity, or true negative rate (TNR): The proportion of true negatives out of all actual negative cases.\n",
    "â¢\tPrecision or positive predictive value (PPV): The proportion of true positives out of all positive predictions made by the model.\n",
    "â¢\tNegative predictive value (NPV): The proportion of true negatives out of all negative predictions made by the model.\n",
    "â¢\tMiss rate or false negative rate (FNR): The proportion of false negatives out of all actual positive cases.\n",
    "â¢\tFall-out or false positive rate (FPR): The proportion of false positives out of all actual negative cases.\n",
    "â¢\tFalse discovery rate (FDR): The proportion of false positives out of all positive predictions made by the model.\n",
    "â¢\tFalse omission rate (FOR): The proportion of false negatives out of all negative predictions made by the model.\n",
    "â¢\tPositive likelihood ratio (LR+): The ratio of true positive rate to false positive rate.\n",
    "â¢\tNegative likelihood ratio (LR-): The ratio of false negative rate to true negative rate.\n",
    "â¢\tPrevalence threshold (PT): A threshold value that balances sensitivity and specificity.\n",
    "â¢\tThreat score (TS) or critical success index (CSI): The proportion of true positives out of all positive and negative predictions made by the model.\n",
    "â¢\tPrevalence: The proportion of positive cases in the data.\n",
    "â¢\tAccuracy (ACC): The proportion of correct predictions (both true positives and true negatives) out of all predictions made by the model.\n",
    "â¢\tBalanced accuracy (BA): The average of sensitivity and specificity.\n",
    "â¢\tF1 score: The harmonic mean of precision and sensitivity, providing a single metric to balance both.\n",
    "â¢\tPhi coefficient (Ï) or Matthews correlation coefficient (MCC): A correlation coefficient that takes into account true positives, true negatives, false positives, and false negatives.\n",
    "â¢\tFowlkes-Mallows index (FM): A geometric mean of precision and sensitivity.\n",
    "â¢\tInformedness or bookmaker informedness (BM): The sum of true positive rate and true negative rate, minus 1.\n",
    "â¢\tMarkedness (MK) or deltaP (Îp): The sum of positive predictive value and negative predictive value, minus 1.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328836ca-2048-4a5a-bc28-bd5a02e16573",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "328836ca-2048-4a5a-bc28-bd5a02e16573",
    "outputId": "6dee34cc-b8b9-4c5a-99be-f450c3b514f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Condition positive (P) for Option 1\\ndata = open_csv_clustered()\\ntrue_job_titles = data[\\'lda_topic\\'].tolist()\\n\\ncondition_positive = 0\\nfor job, _ in similar_jobs:\\n    if job in true_job_titles:\\n        condition_positive += 1\\nprint(\"Option 1/ Condition positive (P) -> The number of real positive cases in the data:\", condition_positive)\\n\\n# Condition positive (P) for Option 2\\ncondition_positive = 0\\nfor i in range(len(jobs)):\\n    avg = averageOfSkills(model, skills[i])\\n    distVec = cdist([avg,], values)\\n    topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\\n    if topJobs[0] == jobs[i]:\\n        condition_positive += 1\\nprint(\"Option 2/ Condition positive (P) -> The number of real positive cases in the data:\", condition_positive)\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL EVALUATION \n",
    "\n",
    "'''\n",
    "# Condition positive (P) for Option 1\n",
    "data = open_csv_clustered()\n",
    "true_job_titles = data['lda_topic'].tolist()\n",
    "\n",
    "condition_positive = 0\n",
    "for job, _ in similar_jobs:\n",
    "    if job in true_job_titles:\n",
    "        condition_positive += 1\n",
    "print(\"Option 1/ Condition positive (P) -> The number of real positive cases in the data:\", condition_positive)\n",
    "\n",
    "# Condition positive (P) for Option 2\n",
    "condition_positive = 0\n",
    "for i in range(len(jobs)):\n",
    "    avg = averageOfSkills(model, skills[i])\n",
    "    distVec = cdist([avg,], values)\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\n",
    "    if topJobs[0] == jobs[i]:\n",
    "        condition_positive += 1\n",
    "print(\"Option 2/ Condition positive (P) -> The number of real positive cases in the data:\", condition_positive)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de62110e-d19b-435c-ac3d-304ccf24742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text_mining', 0.9873502254486084), ('image_processing', 0.9659996032714844), ('computer_vision', 0.9562139511108398), ('logistic_regression', 0.9512531161308289), ('deep_learning', 0.9502419233322144)]\n",
      "0.7980417907238007\n",
      "0.41370654106140137\n",
      "0.473969042301178\n",
      "0.5525058507919312\n",
      "[('image_processing', 0.9678088426589966), ('computer_vision', 0.9677087664604187), ('natural_language_processing', 0.9595919251441956), ('text_mining', 0.9250181317329407), ('sensors', 0.9205660223960876)]\n",
      "0.6411885619163513\n",
      "0.44274401664733887\n",
      "0.3136270046234131\n",
      "0.9719960577785969\n"
     ]
    }
   ],
   "source": [
    "#Training Part\n",
    "\n",
    "# Proper testing\n",
    "import heapq\n",
    "\n",
    "# divide data into 75 train, 25 test\n",
    "def train_test_split(df, frac=0.25):\n",
    "    # get random sample \n",
    "    test = df.sample(frac=frac, axis=0)\n",
    "    # get everything but the test sample\n",
    "    train = df.drop(index=test.index)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "df = open_csv_clustered()\n",
    "\n",
    "df_data, df_test = train_test_split(df)\n",
    "\n",
    "formatted_data = df_data.values.tolist()\n",
    "formatted_test = df_test.values.tolist()\n",
    "jobs, skills = list(zip(*formatted_test))\n",
    "skills = [ast.literal_eval(skill) for skill in skills]\n",
    "\n",
    "#Option 1: Doc2Vec komplett\n",
    "model = trainDoc2Vec(formatted_data)\n",
    "# model.save(\"doc2vec_model.bin\")\n",
    "for i in range(len(jobs)):\n",
    "    infer_vector = model.infer_vector(skills[i])\n",
    "    similar_jobs = model.dv.most_similar([infer_vector], topn=3)\n",
    "\n",
    "#Option 2: Word2Vec komplett\n",
    "job_averages, keys, values, model = prepareOption2(formatted_data)\n",
    "correct = 0\n",
    "top3 = 0\n",
    "for i in range(len(jobs)):\n",
    "    avg = averageOfSkills(model, skills[i])\n",
    "    distVec = cdist([avg,], values)\n",
    "    #sortedList = sorted(list(zip(distVec.transpose(), keys)))\n",
    "    #topJobs = [i for scor,i in sortedList[0:5]]\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]\n",
    "\n",
    "# Option 3: Doc2Vec Embedding \n",
    "job_averages, keys, values, model = prepareOption3(formatted_data)\n",
    "correct = 0\n",
    "top3 = 0\n",
    "for i in range(len(jobs)):\n",
    "    avg = averageOfSkills(model, skills[i])\n",
    "    distVec = cdist([avg,], values)\n",
    "    #sortedList = sorted(list(zip(distVec.transpose(), keys)))\n",
    "    #topJobs = [i for scor,i in sortedList[0:5]]\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(3, zip(distVec.transpose(), keys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2e5ad6-ba1e-44b5-bf1d-54d768a40fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from gensim.models import Word2Vec, Doc2Vec\n",
    "# # from gensim.models.doc2vec import TaggedDocument\n",
    "# # from scipy.spatial.distance import cdist\n",
    "# # import ast\n",
    "# # import numpy as np\n",
    "\n",
    "# # Function to calculate the average vector of a list of skills\n",
    "# def average_of_skills(model, input_skills):\n",
    "#     vectors = [model.wv[skill] for skill in input_skills if skill in model.wv]\n",
    "#     if len(vectors) == 0:\n",
    "#         return np.zeros(model.vector_size)\n",
    "#     return np.average(vectors, axis=0)\n",
    "\n",
    "# # Option 1: Doc2Vec\n",
    "# def calculate_similarity_score_option1(model, input_skills, true_skills):\n",
    "#     input_vector = average_of_skills(model, input_skills)\n",
    "#     true_skill_vectors = [average_of_skills(model, skills) for skills in true_skills]\n",
    "#     similarity_scores = [1 - cdist([input_vector], [true_skill_vector], metric='cosine')[0][0] for true_skill_vector in true_skill_vectors]\n",
    "#     return max(similarity_scores)\n",
    "\n",
    "# # Option 2: Word2Vec\n",
    "# def calculate_similarity_score_option2(model, input_skills, true_skills):\n",
    "#     input_vector = average_of_skills(model, input_skills)\n",
    "#     true_skill_vectors = [average_of_skills(model, skills) for skills in true_skills]\n",
    "#     similarity_scores = [1 - cdist([input_vector], [true_skill_vector], metric='cosine')[0][0] for true_skill_vector in true_skill_vectors]\n",
    "#     return max(similarity_scores)\n",
    "\n",
    "# # Option 3: Word2Vec\n",
    "# def calculate_similarity_score_option3(model, input_skills, true_skills):\n",
    "#     similarity_scores = []\n",
    "#     for skill in input_skills:\n",
    "#         top_jobs = model.wv.most_similar([skill], topn=3)\n",
    "#         job_similarities = [similarity for _, similarity in top_jobs]\n",
    "#         similarity_scores.append(max(job_similarities))\n",
    "#     return max(similarity_scores)\n",
    "\n",
    "# # Load the Doc2Vec model\n",
    "# model_option1 = Doc2Vec.load(\"doc2vec_model.bin\")  # Load Option 1 model\n",
    "\n",
    "# # Load the Word2Vec models\n",
    "# model_option2 = Word2Vec.load(\"word2vec_model_option2.bin\")  # Load Option 2 model\n",
    "# model_option3 = Word2Vec.load(\"doc2vec_model_option3.bin\")  # Load Option 3 model\n",
    "\n",
    "# # Load the data\n",
    "# data = open_csv_clustered()  # Load data\n",
    "# input_skills = [\"skill1\", \"skill2\", \"skill3\"]  # Example input skills\n",
    "# true_skills = [[\"skill4\", \"skill5\", \"skill6\"], [\"skill7\", \"skill8\", \"skill9\"]]  # Example true skills\n",
    "\n",
    "# # Calculate similarity score for Option 1 (Doc2Vec)\n",
    "# similarity_score_option1 = calculate_similarity_score_option1(model_option1, input_skills, true_skills)\n",
    "# print(\"Option 1: Similarity Score:\", similarity_score_option1)\n",
    "\n",
    "# # Calculate similarity score for Option 2 (Word2Vec)\n",
    "# similarity_score_option2 = calculate_similarity_score_option2(model_option2, input_skills, true_skills)\n",
    "# print(\"Option 2: Similarity Score:\", similarity_score_option2)\n",
    "\n",
    "# # Calculate similarity score for Option 3 (Word2Vec)\n",
    "# similarity_score_option3 = calculate_similarity_score_option3(model_option3, input_skills, true_skills)\n",
    "# print(\"Option 3: Similarity Score:\", similarity_score_option3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b16f6e9a-bb78-436b-89f8-366851c4aaf0",
   "metadata": {
    "id": "b16f6e9a-bb78-436b-89f8-366851c4aaf0",
    "outputId": "9658cf1e-f519-4bff-9483-81e3e9fe6f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text_mining', 0.980698823928833), ('computer_vision', 0.9587388038635254), ('deep_learning', 0.9560656547546387), ('logistic_regression', 0.9485481381416321), ('image_processing', 0.9439621567726135)]\n",
      "0.8279450237751007\n",
      "0.4098643660545349\n",
      "0.44455498456954956\n",
      "0.5119906067848206\n",
      "[('computer_vision', 0.9666356444358826), ('natural_language_processing', 0.9600709676742554), ('text_mining', 0.95400470495224), ('image_processing', 0.9429821968078613), ('3d', 0.9346281886100769)]\n",
      "0.6396596729755402\n",
      "0.3815299868583679\n",
      "0.3319798707962036\n",
      "1.0083295674994588\n",
      "Accuracy - Option 1: Doc2Vec komplett: 0.0\n",
      "Accuracy - Option 2: Word2Vec komplett: 0.0\n",
      "Accuracy - Option 3: Doc2Vec Embedding: 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(predictions, labels):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    \n",
    "    for pred, label in zip(predictions, labels):\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Given set of skills\n",
    "#skills = [\"Python, SQL, Machine Learning\", \"Java, JavaScript, Web Development\"]\n",
    "skills = [\"Python, SQL, Machine Learning\"]\n",
    "\n",
    "\n",
    "# Option 1: Doc2Vec komplett\n",
    "model1 = trainDoc2Vec(formatted_data)\n",
    "predictions1 = []\n",
    "\n",
    "for skills in skills:\n",
    "    infer_vector = model1.infer_vector(skills.split(\", \"))  # Split skills into a list\n",
    "    similar_jobs = model1.dv.most_similar([infer_vector], topn=1)\n",
    "    predicted_job = similar_jobs[0][0]\n",
    "    predictions1.append(predicted_job)\n",
    "\n",
    "accuracy1 = evaluate_accuracy(predictions1, jobs)\n",
    "\n",
    "# Option 2: Word2Vec komplett\n",
    "job_averages, keys, values, model2 = prepareOption2(formatted_data)\n",
    "predictions2 = []\n",
    "\n",
    "for skills in skills:\n",
    "    avg = averageOfSkills(model2, skills.split(\", \"))  # Split skills into a list\n",
    "    distVec = cdist([avg], values)\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(1, zip(distVec.transpose(), keys))]\n",
    "    predicted_job = topJobs[0]\n",
    "    predictions2.append(predicted_job)\n",
    "\n",
    "accuracy2 = evaluate_accuracy(predictions2, jobs)\n",
    "\n",
    "# Option 3: Doc2Vec Embedding\n",
    "job_averages, keys, values, model3 = prepareOption3(formatted_data)\n",
    "predictions3 = []\n",
    "\n",
    "for skills in skills:\n",
    "    avg = averageOfSkills(model3, skills.split(\", \"))  # Split skills into a list\n",
    "    distVec = cdist([avg], values)\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(1, zip(distVec.transpose(), keys))]\n",
    "    predicted_job = topJobs[0]\n",
    "    predictions3.append(predicted_job)\n",
    "\n",
    "accuracy3 = evaluate_accuracy(predictions3, jobs)\n",
    "\n",
    "# Compare accuracies\n",
    "print(\"Accuracy - Option 1: Doc2Vec komplett:\", accuracy1)\n",
    "print(\"Accuracy - Option 2: Word2Vec komplett:\", accuracy2)\n",
    "print(\"Accuracy - Option 3: Doc2Vec Embedding:\", accuracy3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ef591a1-0d98-4da9-9c8a-4e7c6e68dcf3",
   "metadata": {
    "id": "5ef591a1-0d98-4da9-9c8a-4e7c6e68dcf3"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "XA and XB must have the same number of columns (i.e. feature dimension.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25456/2468672820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverageOfSkills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdistVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mtopJobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistVec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpredicted_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopJobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2918\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'XB must be a 2-dimensional array.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2919\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2920\u001b[1;33m         raise ValueError('XA and XB must have the same number of columns '\n\u001b[0m\u001b[0;32m   2921\u001b[0m                          '(i.e. feature dimension.)')\n\u001b[0;32m   2922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: XA and XB must have the same number of columns (i.e. feature dimension.)"
     ]
    }
   ],
   "source": [
    "# Given dataset\n",
    "dataset = [\n",
    "    (\"Research Data Scientist\", ['machine_learning', 'python', 'it_skills', 'software_development', 'data_science', 'cloud', 'logistic_regression', 'nosql']),\n",
    "    (\"GAMMA Lead Data Scientist\", ['data_analysis', 'operations_research', 'data_science', 'data_management', 'business_analytics', 'consulting', 'management_consulting', 'business_strategy']),\n",
    "    (\"Staff Engineer Data Scientist\", ['computer_science', 'text_mining', 'data_analysis', 'machine_learning', 'shell_scripting', 'oracle', 'forecasting', 'ieee'])\n",
    "]\n",
    "\n",
    "# Initialize lists to store true labels and predictions\n",
    "true_labels = []\n",
    "predictions1 = []\n",
    "predictions2 = []\n",
    "predictions3 = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for job, skills in dataset:\n",
    "    # Append the true label to the true_labels list\n",
    "    true_labels.append(job)\n",
    "\n",
    "    # Perform predictions for each option and append to respective prediction lists\n",
    "    infer_vector = model1.infer_vector(skills)\n",
    "    similar_jobs = model1.dv.most_similar([infer_vector], topn=1)\n",
    "    predicted_job = similar_jobs[0][0]\n",
    "    predictions1.append(predicted_job)\n",
    "\n",
    "    avg = averageOfSkills(model2, skills)\n",
    "    distVec = cdist([avg], values)\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(1, zip(distVec.transpose(), keys))]\n",
    "    predicted_job = topJobs[0]\n",
    "    predictions2.append(predicted_job)\n",
    "\n",
    "    avg = averageOfSkills(model3, skills)\n",
    "    distVec = cdist([avg], values)\n",
    "    topJobs = [k for dist, k in heapq.nsmallest(1, zip(distVec.transpose(), keys))]\n",
    "    predicted_job = topJobs[0]\n",
    "    predictions3.append(predicted_job)\n",
    "\n",
    "# Create the confusion matrices\n",
    "confusion_matrix1 = confusion_matrix(true_labels, predictions1)\n",
    "confusion_matrix2 = confusion_matrix(true_labels, predictions2)\n",
    "confusion_matrix3 = confusion_matrix(true_labels, predictions3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af114b38-fc42-4537-b9dd-b036fb856e52",
   "metadata": {
    "id": "af114b38-fc42-4537-b9dd-b036fb856e52",
    "outputId": "68867287-7d87-47ef-bbbc-4d6c9927034a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb4611-258f-4677-8a7f-875f55ddef4b",
   "metadata": {
    "id": "73bb4611-258f-4677-8a7f-875f55ddef4b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bb76c-037e-476b-be33-8591222bd8b9",
   "metadata": {
    "id": "f01bb76c-037e-476b-be33-8591222bd8b9",
    "outputId": "4671c668-0d2b-4887-a761-aacd6688a4d7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cdf5d-ed5b-43b2-945b-383f4421b2b6",
   "metadata": {
    "id": "be6cdf5d-ed5b-43b2-945b-383f4421b2b6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ad77b-4f27-4131-aa9f-0522b1cf6280",
   "metadata": {
    "id": "175ad77b-4f27-4131-aa9f-0522b1cf6280"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c0457-9e97-485c-b125-1d0a80e6b7e6",
   "metadata": {
    "id": "695c0457-9e97-485c-b125-1d0a80e6b7e6",
    "outputId": "8c1576ae-e06e-4d10-befc-fd95b2ffdc77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db0488-11a9-49fe-9b7c-94227a7727e7",
   "metadata": {
    "id": "e5db0488-11a9-49fe-9b7c-94227a7727e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab1308-e5c4-4f69-b114-9d0d107b2e19",
   "metadata": {
    "id": "65ab1308-e5c4-4f69-b114-9d0d107b2e19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b31c35-8bae-40a3-87a5-6c94732b05e7",
   "metadata": {
    "id": "13b31c35-8bae-40a3-87a5-6c94732b05e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a6ead-8519-4bd5-89f0-d05b0ec21d4b",
   "metadata": {
    "id": "d11a6ead-8519-4bd5-89f0-d05b0ec21d4b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
