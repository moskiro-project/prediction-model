{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a74965-7c85-4d75-be00-9068d7a967dd",
   "metadata": {},
   "source": [
    "# Modelle (Word2Vec, Doc2Vec) sowie Evaluation aller Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e7030c-3a8c-4a74-b549-87489393fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Datenaufbereitung\\n2. Methodendeklaration, Hilfsfunktion, unsw.\\n3. Training (Word2Vec, Doc2Vec)\\n4. Laden der Training-Ergebnisse von LinkPred, Knowledge Graph\\n5. Testing aller Modelle (Word2Vec, Doc2Vec, LinkPred, Know. Graph)\\n6. Weitere Beispielvorführung\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inhaltverzeichnis:\n",
    "'''\n",
    "1. Datenaufbereitung\n",
    "2. Methodendeklaration, Hilfsfunktion, unsw.\n",
    "3. Training (Word2Vec, Doc2Vec)\n",
    "4. Laden der Training-Ergebnisse von LinkPred, Knowledge Graph\n",
    "5. Testing aller Modelle (Word2Vec, Doc2Vec, LinkPred, Know. Graph)\n",
    "6. Weitere Beispielvorführung\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f1854-0b14-4c93-b1b2-ccef2e425d6c",
   "metadata": {},
   "source": [
    "## *1. Datenaufbereitung*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc8c7a76-ca00-4b83-94f2-01ef7f63b62f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3973980704.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[27], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    pip install --upgrade --force-reinstall gensim\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27255109-b67f-45e4-8c7c-20aad52e1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --force-reinstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160d14d7-56c7-4e27-84c2-5c8c24f53932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from LinkPred import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7a7f37-7baf-4405-afca-5222c96e89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(column):\n",
    "    return str(column).split(\",\")\n",
    "\n",
    "def open_csv_training():\n",
    "    df_data = pd.read_csv(\"data\\Complete_Data_Clustered_Cleaned.csv\")\n",
    "    df_data = df_data.drop(columns=['Unnamed: 0', 'JobTitle', 'Description', 'Skills/Description'])\n",
    "    df_data = df_data[['Cluster', 'NewSkills_lowercase']]\n",
    "    return df_data\n",
    "\n",
    "def open_csv_testdata():\n",
    "    df_data = pd.read_csv(\"data\\Complete_Data_Clustered_Cleaned_test.csv\")\n",
    "    df_data = df_data.drop(columns=['Unnamed: 0', 'JobTitle', 'Description', 'Skills/Description'])\n",
    "    df_data = df_data[['Cluster', 'NewSkills_lowercase']]\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9bd0c8-3c33-4768-be0f-5331279b26f0",
   "metadata": {},
   "source": [
    "## *2. Methodendeklaration, Hilfsfunktion, unsw.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e07cf8e-70fb-4b6f-b6a3-9fb558841c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training uses the Doc2Vec or Word2Vec model which simply embeds words according to how often they occur together (ignoring order afaik)\n",
    "## Adapt vector size and epochs in training once data set is complete\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import ast\n",
    "import numpy\n",
    "\n",
    "def trainWord2Vec(data):\n",
    "# Preprocess the data and create list of skills (this training does NOT include jobs!)\n",
    "    tagged_data = [ast.literal_eval(skills) for job, skills in data]\n",
    "\n",
    "# Train the Word2Vec model, try different vector sizes for interesting effects in similarities\n",
    "    model = Word2Vec(vector_size=50, min_count=1, workers=4, epochs=20)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "def trainDoc2Vec(data):\n",
    "    tagged_data = [TaggedDocument(words=ast.literal_eval(skills), tags=[job]) for job, skills in data[:]]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "# helper method to calculate average embedding vector of a list of string skills, filters out skills unknown to the model\n",
    "def averageOfSkills(model, input, axis = 0):\n",
    "    vectors = [model.wv[i] for i in input if model.wv.has_index_for(i)]\n",
    "    if(len(vectors) == 0):\n",
    "        return numpy.zeros(len(model.wv[0]))\n",
    "    return numpy.average(vectors, axis = axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6acefa7f-0518-4f87-b472-e48543ce780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def calcAvgEmbeddings(model, data):\n",
    "    # Tests for the embedding go here\n",
    "    # print(model.wv.most_similar(\"neural_networks\", topn = 5))\n",
    "\n",
    "    # split the tuples\n",
    "    job_titles, skills = list(zip(*data))\n",
    "    # calculate the average skill vector of every job offering / person and zip back together\n",
    "    skillAverages = [averageOfSkills(model, ast.literal_eval(skill)) for skill in skills]\n",
    "    data_averaged = list(zip(job_titles, skillAverages))\n",
    "\n",
    "    return (skillAverages, data_averaged)\n",
    "\n",
    "# This gives us a list of job offerings and average embeddings. \n",
    "# Could be used as input to a graph neural network or knowledge graph?\n",
    "# Is used below to classify immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535bf8cc-b2c5-4e58-8850-f51c92ec0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply suggest smallest distance to user's average (\"Option 2\") using word2Vec\n",
    "import itertools\n",
    "import operator\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def prepareOption2(data):\n",
    "    model = trainWord2Vec(data)\n",
    "    skillAverages, data_averaged = calcAvgEmbeddings(model, data)\n",
    "\n",
    "    # sort before grouping\n",
    "    data_averaged.sort(key=operator.itemgetter(0))\n",
    "    # Group by job title, take the average embedding of everyone with that title and make a dictionary (maps job title to average embedding)\n",
    "    job_averages = {key : numpy.average(list(zip(*list(value)))[1], axis = 0)\n",
    "        for key, value in itertools.groupby(data_averaged, lambda x: x[0])}\n",
    "\n",
    "    #keep keys and values\n",
    "    keys = list(job_averages.keys())\n",
    "    values = list(job_averages.values())\n",
    "    # easy access to the avg vector\n",
    "    #print(job_averages['Advisor, Data Science'])\n",
    "    \n",
    "    # model.save(\"word2vec_model_option2.bin\")\n",
    "    return job_averages, keys, values, model\n",
    "\n",
    "# usage in next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5390225b-3dbb-440a-91d9-872e5bbce6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Option 3\" could be using the embedding learned by Doc2Vec and doing the same manual averaging as Option 2 for \"learning\" the correlation of job to skills\n",
    "import itertools\n",
    "import operator\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "def prepareOption3(data):\n",
    "#if !data:\n",
    "#  data = open_csv_clean()\n",
    "    model = trainDoc2Vec(data)\n",
    "    skillAverages, data_averaged = calcAvgEmbeddings(model, data)\n",
    "\n",
    "    # sort before grouping\n",
    "    data_averaged.sort(key=operator.itemgetter(0))\n",
    "    # Group by job title, take the average embedding of everyone with that title and make a dictionary (maps job title to average embedding)\n",
    "    job_averages = {key : numpy.average(list(zip(*list(value)))[1], axis = 0)\n",
    "        for key, value in itertools.groupby(data_averaged, lambda x: x[0])}\n",
    "\n",
    "    #keep keys and values\n",
    "    keys = list(job_averages.keys())\n",
    "    values = list(job_averages.values())\n",
    "    \n",
    "    return job_averages, keys, values, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d19b6-0345-4e41-9fb8-2b08e68d7180",
   "metadata": {},
   "source": [
    "## *3. Training (Word2Vec, Doc2Vec)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b0c592-5d4d-4537-9f53-dfd6a76f27a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFull Dataset length = 5030\\nTrainingSet length = 4024 (80%)\\nTestSet length = 1006 (20%)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% training, 20% testing\n",
    "'''\n",
    "Full Dataset length = 5030\n",
    "TrainingSet length = 4024 (80%)\n",
    "TestSet length = 1006 (20%)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c47e2f1-2cf5-4f6f-9e41-6baed42f206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training mit seperaten Excel Dateien\n",
    "import heapq\n",
    "\n",
    "trainingdata = open_csv_training()\n",
    "testingdata = open_csv_testdata()\n",
    "\n",
    "formatted_data = trainingdata.values.tolist()\n",
    "formatted_test = testingdata.values.tolist()\n",
    "jobs, skills = list(zip(*formatted_test))\n",
    "skills = [ast.literal_eval(skill) for skill in skills]\n",
    "\n",
    "# Option 1: Doc2Vec\n",
    "model_option1 = trainDoc2Vec(formatted_data)\n",
    "\n",
    "# Option 2: Word2Vec\n",
    "job_averages_option2, keys_option2, values_option2, model_option2 = prepareOption2(formatted_data)\n",
    "\n",
    "# Option 3: Doc2Vec Embedding\n",
    "job_averages_option3, keys_option3, values_option3, model_option3 = prepareOption3(formatted_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77a912-42ab-48a7-883f-07f5c565677f",
   "metadata": {},
   "source": [
    "## *4. Laden der Training-Ergebnisse von LinkPred, Knowledge Graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19898036-531c-4e92-924a-6f8822453825",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkpred = model(load_model=True,save_model=False,load_test=True)\n",
    "linkpred_out = linkpred.test(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414896b-b991-47cb-a21a-5d34bddbc874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37097b7-fc9f-40e7-b51f-4b19044f2d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f95cd0-180c-4232-8867-8e44be2e2b0f",
   "metadata": {},
   "source": [
    "## *5. Testing aller Modelle (Word2Vec, Doc2Vec, LinkPred, Know. Graph)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8de702-fc3c-4f07-b917-15e120093b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Doc2Vec\n",
    "predictions_option1 = []\n",
    "for skills_example in skills:\n",
    "    infer_vector_option1 = model_option1.infer_vector(skills_example)\n",
    "    similar_jobs_option1 = model_option1.dv.most_similar([infer_vector_option1], topn=3)\n",
    "    predicted_jobs_option1 = [job for job, similarity in similar_jobs_option1]\n",
    "    predictions_option1.append(predicted_jobs_option1)\n",
    "\n",
    "# Option 2: Word2Vec\n",
    "predictions_option2 = []\n",
    "for skills_example in skills:\n",
    "    avg_option2 = averageOfSkills(model_option2, skills_example)\n",
    "    distVec_option2 = cdist([avg_option2], values_option2)\n",
    "    topJobs_option2 = [k for dist, k in heapq.nsmallest(3, zip(distVec_option2.transpose(), keys_option2))]\n",
    "    predictions_option2.append(topJobs_option2)\n",
    "\n",
    "# Option 3: Doc2Vec Embedding\n",
    "predictions_option3 = []\n",
    "for skills_example in skills:\n",
    "    avg_option3 = averageOfSkills(model_option3, skills_example)\n",
    "    distVec_option3 = cdist([avg_option3], values_option3)\n",
    "    topJobs_option3 = [k for dist, k in heapq.nsmallest(3, zip(distVec_option3.transpose(), keys_option3))]\n",
    "    predictions_option3.append(topJobs_option3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629fda8-9cc4-476c-ab62-662eea8184ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "• True positive (TP): A test result that correctly indicates the presence of a condition or characteristic.\n",
    "• False positive (FP): A test result that wrongly indicates that a particular condition or attribute is present.\n",
    "'''\n",
    "\n",
    "# job[0] is the label/correct job category\n",
    "ground_truth_labels = [job[0] for job in formatted_test]\n",
    "\n",
    "# Option 1\n",
    "tp_option1 = 0\n",
    "fp_option1 = 0\n",
    "\n",
    "# Iterate over predicted job titles and ground truth labels\n",
    "for predicted_jobs, ground_truth in zip(predictions_option1, ground_truth_labels):\n",
    "    if ground_truth in predicted_jobs:\n",
    "        tp_option1 += 1\n",
    "    else:\n",
    "        fp_option1 += 1\n",
    "\n",
    "# Option 2\n",
    "tp_option2 = 0\n",
    "fp_option2 = 0\n",
    "\n",
    "# Iterate over predicted job titles and ground truth labels\n",
    "for predicted_jobs, ground_truth in zip(predictions_option2, ground_truth_labels):\n",
    "    if ground_truth in predicted_jobs:\n",
    "        tp_option2 += 1\n",
    "    else:\n",
    "        fp_option2 += 1\n",
    "\n",
    "# Option 3\n",
    "tp_option3 = 0\n",
    "fp_option3 = 0\n",
    "\n",
    "# Iterate over predicted job titles and ground truth labels\n",
    "for predicted_jobs, ground_truth in zip(predictions_option3, ground_truth_labels):\n",
    "    if ground_truth in predicted_jobs:\n",
    "        tp_option3 += 1\n",
    "    else:\n",
    "        fp_option3 += 1\n",
    "\n",
    "print(\"Option 1:\")\n",
    "print(\"True Positives (TP):\", tp_option1)\n",
    "print(\"False Positives (FP):\", fp_option1)\n",
    "\n",
    "print(\"\\nOption 2:\")\n",
    "print(\"True Positives (TP):\", tp_option2)\n",
    "print(\"False Positives (FP):\", fp_option2)\n",
    "\n",
    "print(\"\\nOption 3:\")\n",
    "print(\"True Positives (TP):\", tp_option3)\n",
    "print(\"False Positives (FP):\", fp_option3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6279851-1668-468b-8317-82ca652bea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "• Accuracy (ACC): The proportion of correct predictions (both true positives and true negatives) out of all predictions made by the model.\n",
    "• Precision or positive predictive value (PPV): The proportion of true positives out of all positive predictions made by the model.\n",
    "'''\n",
    "# Calculate precision (PPV)\n",
    "precision_option1 = tp_option1 / (tp_option1 + fp_option1)\n",
    "precision_option2 = tp_option2 / (tp_option2 + fp_option2)\n",
    "precision_option3 = tp_option3 / (tp_option3 + fp_option3)\n",
    "\n",
    "# Calculate accuracy (ACC)\n",
    "total_predictions = len(ground_truth_labels)\n",
    "correct_predictions_option1 = tp_option1\n",
    "correct_predictions_option2 = tp_option2\n",
    "correct_predictions_option3 = tp_option3\n",
    "accuracy_option1 = correct_predictions_option1 / total_predictions\n",
    "accuracy_option2 = correct_predictions_option2 / total_predictions\n",
    "accuracy_option3 = correct_predictions_option3 / total_predictions\n",
    "\n",
    "print(\"Option 1:\")\n",
    "print(\"True Positives (TP):\", tp_option1)\n",
    "print(\"False Positives (FP):\", fp_option1)\n",
    "print(\"Precision (PPV):\", precision_option1)\n",
    "print(\"Accuracy (ACC):\", accuracy_option1)\n",
    "\n",
    "print(\"\\nOption 2:\")\n",
    "print(\"True Positives (TP):\", tp_option2)\n",
    "print(\"False Positives (FP):\", fp_option2)\n",
    "print(\"Precision (PPV):\", precision_option2)\n",
    "print(\"Accuracy (ACC):\", accuracy_option2)\n",
    "\n",
    "print(\"\\nOption 3:\")\n",
    "print(\"True Positives (TP):\", tp_option3)\n",
    "print(\"False Positives (FP):\", fp_option3)\n",
    "print(\"Precision (PPV):\", precision_option3)\n",
    "print(\"Accuracy (ACC):\", accuracy_option3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0430aae-957b-4877-9b66-2f2f9cb16791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisierung der Ergebnisse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy values for the three options\n",
    "accuracies = [accuracy_option1, accuracy_option2, accuracy_option3]\n",
    "\n",
    "# Labels for the x-axis\n",
    "options = ['Option 1', 'Option 2', 'Option 3']\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.bar(options, accuracies)\n",
    "#plt.xlabel('Options')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylim([0, 1])  # Set the y-axis limits between 0 and 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43595206-f507-41a3-bed9-57ca7560dbc5",
   "metadata": {},
   "source": [
    "## *6. Weitere Beispielvorführung*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f158b-a8e2-4f83-8363-b9aa1cc90236",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_example = ['cad', 'maschinenbau', 'kostruktion', 'fräsen', 'drehen', 'montieren']\n",
    "\n",
    "# Option 1: Doc2Vec\n",
    "infer_vector_option1 = model_option1.infer_vector(skills_example)\n",
    "similar_jobs_option1 = model_option1.dv.most_similar([infer_vector_option1], topn=3)\n",
    "predicted_jobs_option1 = [job for job, similarity in similar_jobs_option1]\n",
    "print(\"Option 1 Prediction: Given the skillset, it should belong to one of the following three groups beginning with the best match:\", predicted_jobs_option1)\n",
    "print(\"\")\n",
    "\n",
    "# Option 2: Word2Vec\n",
    "avg_option2 = averageOfSkills(model_option2, skills_example)\n",
    "distVec_option2 = cdist([avg_option2], values_option2)\n",
    "topJobs_option2 = [k for dist, k in heapq.nsmallest(3, zip(distVec_option2.transpose(), keys_option2))]\n",
    "print(\"Option 2 Prediction: Given the skillset, it should belong to one of the following three groups beginning with the best match:\", topJobs_option2)\n",
    "print(\"\")\n",
    "\n",
    "# Option 3: Doc2Vec Embedding\n",
    "avg_option3 = averageOfSkills(model_option3, skills_example)\n",
    "distVec_option3 = cdist([avg_option3], values_option3)\n",
    "topJobs_option3 = [k for dist, k in heapq.nsmallest(3, zip(distVec_option3.transpose(), keys_option3))]\n",
    "print(\"Option 3 Prediction: Given the skillset, it should belong to one of the following three groups beginning with the best match:\", topJobs_option3)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf84f56-ab2c-4b32-a5f9-4f5523d63365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b6b43-98d3-4e7b-a6cf-27bc58e2dedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}